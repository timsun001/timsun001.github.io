[{"content":"前情提要 在上一篇关于小红书笔记标题聚类的研究中，我们用BERT输出初步的分类结果，再用T-SNE对分类结果做了降维，最后根据各笔记的分布密度识别出了“妆容教程类”、“二手交易类”和“商业推广类”三类笔记。 显然，最后一步非常依赖人的判断，难以规模化并且不太客观。\n基于点密度的聚类算法 本次我们在之前的基础上增加了基于DBSCAN的聚类（DBSCAN是基于点密度的分类算法，通过“同类内的最小距离”（eps）和“最小样本数”(min_samples)来调节聚类效果）。 相较于传统的KMeans算法（通过指定集群数量来调节聚类效果），该算法具有以下优势：\n无需指定集群数量（很显然我们是无法知道小红书标题中集群的总数的） 没有明显集群关系的点会被归至其他类 同时，运用该算法也要克服一个挑战，即如何找到合适的eps及min_samples参数。\n参数调优 将轮廓系数作为评价指标 显然，如果eps或min_samples设置的过大，会导致大量的点被分至同一类进而丢失有效信息，反之亦然。 为解决这一问题，我们首先引入“轮廓系数”作为算法的评价指标，测试不同参数下的“轮廓系数”大小。理想情况下，“轮廓系数”越大越好（说明分类界限越分明）。然而，在上述任务中，轮廓系数大可能引起两方面的负面影响：\n分类总数变少 “其他”类中的样本数变多 引入“其他类样本占比”和“分类总数”来优化评价指标 为克服上述负面影响，我们引入了“其他类样本占比”，用此指标与轮廓系数求调和平均作为聚类评分值（越大越好）。同时我们计算了不同参数下的分类总数。下表展示了部分参数下的聚类评分值（weighted_silhouette）。 我们最终选取的是n_labels大于10中weighted_silhouette最大的方案。最终聚类效果如下图。可见，我们不仅清晰区分出了此前方案已识别出的“妆容教程类”、“二手交易类”和“商业推广类”三类笔记，还额外识别出了额外的7类笔记。 附录 轮廓系数 轮廓系数是一种用于评估聚类质量的指标，旨在衡量聚类结果中样本的紧密度和分离度。它可以帮助我们了解聚类算法对数据的划分效果如何，即样本是否被正确地分为相似的簇并且不同的簇之间有明显的区别。\n具体来说，对于每个样本，轮廓系数考虑了两个因素：\n样本与同一簇中其他样本的相似程度：衡量了样本与其簇内其他样本之间的平均距离。这个值越小，说明样本在其所属的簇内越紧密，聚类效果越好。\n样本与最近邻不同簇中样本的相似程度：衡量了样本与其最近邻的其他簇之间的平均距离。这个值越大，说明样本与其它簇的样本之间的距离越远，聚类效果越好。\n综合考虑这两个因素，轮廓系数的取值范围在[-1, 1]之间：\n一个较高的正值表示样本与其簇内样本更接近，同时与其他簇的样本距离较远，表示聚类效果较好。 一个接近于零的值表示样本与其簇内样本的距离近似于与其他簇的样本距离，聚类效果不明确。 一个负值表示样本更接近于其它簇的样本，聚类效果不好。 因此，轮廓系数越接近于1，聚类效果越好，越接近于-1或小于0，聚类效果越差。在使用轮廓系数时，我们希望找到最高的轮廓系数，以获得最优的聚类结果。\n在Tableau Public查看可交互的数据 https://public.tableau.com/app/profile/t.s1480/viz/_16905304270770/sheet0\n","date":"2023-07-27T00:00:00Z","image":"https://timsun001.github.io/p/s2/cover_hu5d484754d5be117c65767436165a93f4_160414_120x120_fill_box_smart1_3.png","permalink":"https://timsun001.github.io/p/s2/","title":"基于点密度的聚类算法"},{"content":"\n","date":"2023-07-21T00:00:00Z","image":"https://timsun001.github.io/p/r2/cover_hu6ce8bc9300fe25cb06c817f33c389bce_1209700_120x120_fill_box_smart1_3.png","permalink":"https://timsun001.github.io/p/r2/","title":"揭秘小红书美妆行业种草之争"},{"content":"一、社交电商时代的NLP信息挖掘 小红书笔记数据中蕴含大量信息，但其内容往往较为发散。如果能聚焦到其中与消费决策相关的部分，则可以帮助消费品品牌更了解消费者，提升产品研发和营销的效率。\n使用传统的分词统计词频方法很难识别不同信息间的差异。 本文介绍了一种方法，来对小红书中的各类信息进行高效且效果显著的聚类。\n二、对比三种分析方案：词频统计、词义聚类和句义聚类 三种方法采用的模型 1. 词频统计 词频统计是最传统的NLP分析方法。在此任务中，其表现不佳，主要因为以下两方面问题：\n出现次数靠前的词多是无语义的助词或标点 由于小红书平台话题高度分散，大量有语义的词出现次数较低 2. 词义聚类 基于词义的聚类基本原理是：\n将句子拆分成词 将词编码，每个编码定义为句子的一个维度（若句子中出现了某词，则在该词的维度记1，反之记0） 使用聚类算法计算句子间的相似度，或是使用降维算法将将高维信息映射至二维以便可视化展示。为了方便直观理解，我们选用了后者（降维）的方法 基于词义的聚类存在以下局限性：\n未考虑词本身的相关性。而如果要做近义词的修正又要涉及大量的人工标注工作 词聚类的结果反映出的最显著信息与词频统计的结果高度相似，缺少信息量 词聚类的结果可能会聚焦于词级别的含义，而缺少句级别的理解时词级别的含义借鉴意义较小。比如图中A区域的共性是都提到了“女大学生”，B区域的共性是都提到了“修容”，C区域的共性是都提到了“高光”，D区域的共性是都提到了“花西子”。这些共性对品牌做营销决策的参考价值很低 3. 句义聚类 基于句义聚类的核心思想是采用预训练的NLP模型，结合一定程度的fine-tune来实现对句义的更准确理解。 我们采用了BERT(BERT是GOOGLE实验室在2018年发布的基于注意力机制的NLP模型)，在未进行任何fine-tune的情况下，其聚类结果已经相当理想。 其基本原理如下：\n选取合适的预训练模型 这里选取的BERT的输出中的第一位代表句子分类，共有768个维度，每个维度中均可在0～1间取值（相当于BERT的输出会将句子分成最多768个类，每个维度中的值代表句子被分为某类的概率） 使用聚类算法计算句子间的相似度，或是使用降维算法将将高维信息映射至二维以便可视化展示。为了方便直观理解，我们选用了后者（降维）的方法 应用此方法，我们发现两个品牌在A、B、C三个区域的笔记数有显著差异。这三个区域分别是： A. 妆容教程类笔记 B. 二手交易类笔记 C. 商业推广类笔记 相较词义聚类的结果，句义聚类对信息的理解更加宏观且更加贴近人类直觉。\n三、句义聚类的优化空间 基于上述句义聚类的结果，如果辅以进一步的人工标注，并基于小红书的语料对BERT模型进行fine-tune，预计能取得更加符合预期的结果。\n","date":"2023-07-15T00:00:00Z","image":"https://timsun001.github.io/p/s1/cover_hu5c588fa652e57b4ca8a674a4435d1023_326333_120x120_fill_box_smart1_3.png","permalink":"https://timsun001.github.io/p/s1/","title":"小红书笔记语义信息挖掘"},{"content":"\n","date":"2023-07-03T00:00:00Z","image":"https://timsun001.github.io/p/r1/cover_huc61380b9affb4552179f0c0e0a25f7fe_311706_120x120_fill_box_smart1_3.png","permalink":"https://timsun001.github.io/p/r1/","title":"抖音电商零食销售新趋势"}]